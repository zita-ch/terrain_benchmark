{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "seed = 2333\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "np.random.seed(seed) \n",
    "\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "from tensorflow.keras.models import load_model\n",
    "import cv2\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.random.set_seed(seed)\n",
    "with tf.device('/cpu:0'):\n",
    "    generator = load_model('terrain_generator50000.h5')\n",
    "    \n",
    "def proxy(points,show=False):\n",
    "    if points is None:\n",
    "        points = []\n",
    "    source = np.zeros((225,225,2))\n",
    "    for p in points:\n",
    "        source[int((p[1]+0.5)*224),int((p[0]+0.5)*224),int(p[2]<0)]=1\n",
    "    source = source[None]\n",
    "    w_noise = np.random.normal(0, 1, (1, 14, 14, 1024))\n",
    "    with tf.device('/cpu:0'):\n",
    "        predicted = generator.predict([source, w_noise])\n",
    "    # im = np.uint8(predicted[0, ...] * 127.5 + 127.5) #[-1,1->0,255]\n",
    "    real_height = predicted[0, ...] \n",
    "    real_height = cv2.GaussianBlur(real_height,(5,5),1.0)* 12.5 + 12.5 # -> 0-25cm # smooth\n",
    "    if show:\n",
    "        plt.figure(figsize=(14,4))\n",
    "        plt.subplot(1,3,1)\n",
    "        plt.imshow(predicted[0],cmap='terrain',norm = colors.Normalize(vmin=-1, vmax=1))\n",
    "        plt.subplot(1,3,2)\n",
    "        plt.imshow(source[0,...,0])\n",
    "        plt.subplot(1,3,3)\n",
    "        plt.imshow(source[0,...,1])\n",
    "    elev = real_height[:,:]\n",
    "    cellsize = 2.5\n",
    "    px, py = np.gradient(elev, cellsize)\n",
    "    slope = np.sqrt(px ** 2 + py ** 2)\n",
    "    slope = np.abs(np.arctan(slope)/np.pi*2)   \n",
    "    score = 0.3 * np.std(slope) + 0.5 * np.mean(slope)**2 + 0.2 * np.mean(np.abs(elev-np.mean(elev)))/25\n",
    "    return score\n",
    "\n",
    "a_dim = 75*75*2+1 # 0:5625, add peak; 5625:11250, add pit; 11250 terminate\n",
    "def decode_action(i):\n",
    "    \"\"\"\n",
    "    input: int i in range(0,11251)\n",
    "    return: none for terminate 11250, else normalized 3d vector in [-1, 1]\n",
    "    \"\"\"\n",
    "    if i == 11250:\n",
    "        return None # terminate\n",
    "    z = 1 if i < 5625 else -1 # peak or pit\n",
    "    x = (i%5625)%75\n",
    "    y = (i%5625)//75\n",
    "    return [(x-37)/74, (y-37)/74, z]\n",
    "\n",
    "def encode_state(s):\n",
    "    \"\"\"\n",
    "    input: none for blank, normalized vectors of (n,3) for point lists\n",
    "    output: a set of used points for action numbers\n",
    "    \"\"\"\n",
    "    if not s:\n",
    "        return []\n",
    "    points1 = [int((p[0]*74+37) + (p[1]*74+37)*75) for p in s]\n",
    "    points2 = [int((p[0]*74+37) + (p[1]*74+37)*75) + 75 * 75 for p in s]\n",
    "    return points1 + points2\n",
    "\n",
    "def decode_state(s):\n",
    "    \"\"\"\n",
    "    input: a dict that has keys in range(0,5625) and values in {-1,1}, can be empty\n",
    "    return: normalized 3-d vectors for each point (element), of shape n*3, can be None for empty dict\n",
    "    \"\"\"\n",
    "    if len(s)==0:\n",
    "        return None\n",
    "    keys, values = s.keys(), list(s.values())\n",
    "    return np.array([[(k%75-37.)/74. for k in keys],[(k//75-37.)/74. for k in keys],values]).T\n",
    "\n",
    "print(proxy(decode_state({132:1,2222:1,3333:1,4444:1,5555:-1,2333:-1,1322:-1}),show=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import copy\n",
    "import random\n",
    "import time\n",
    "\n",
    "random.seed(seed) \n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device0 = torch.device('cuda:0')\n",
    "class flog(nn.Module):\n",
    "    def __init__(self,learned_dim=128,num_head=4):\n",
    "        super(flog, self).__init__()\n",
    "        self.learned_dim = learned_dim\n",
    "\n",
    "        self.learned_start = nn.parameter.Parameter(torch.randn(size=(1,learned_dim),device=device0), requires_grad=True)\n",
    "        self.learned_ter = nn.parameter.Parameter(torch.randn(size=(learned_dim,),device=device0), requires_grad=True)\n",
    "        \n",
    "        self.s_embedding = nn.Linear(4, learned_dim, device=device0)\n",
    "        self.a_embedding = nn.Linear(3, learned_dim, device=device0)\n",
    "        \n",
    "        self.s_q1 = nn.Linear(learned_dim, learned_dim, bias=False, device=device0)\n",
    "        self.s_k1 = nn.Linear(learned_dim, learned_dim, bias=False, device=device0)\n",
    "        self.s_v1 = nn.Linear(learned_dim, learned_dim, bias=False, device=device0)\n",
    "        self.s_enc1 = nn.MultiheadAttention(learned_dim, num_head, batch_first=True, device=device0)\n",
    "        \n",
    "        self.ff1 = nn.Linear(learned_dim, learned_dim, device=device0)\n",
    "        \n",
    "        self.s_q2 = nn.Linear(learned_dim, learned_dim, bias=False, device=device0)\n",
    "        self.s_k2 = nn.Linear(learned_dim, learned_dim, bias=False, device=device0)\n",
    "        self.s_v2 = nn.Linear(learned_dim, learned_dim, bias=False, device=device0)\n",
    "        self.s_enc2 = nn.MultiheadAttention(learned_dim, num_head, batch_first=True, device=device0)\n",
    "        \n",
    "        self.ff2 = nn.Linear(learned_dim, learned_dim, device=device0)\n",
    "        \n",
    "        self.a_q = nn.Linear(learned_dim, learned_dim, bias=False, device=device0)\n",
    "        self.a_sk = nn.Linear(learned_dim, learned_dim, bias=False, device=device0)\n",
    "        self.a_sv = nn.Linear(learned_dim, learned_dim, bias=False, device=device0)        \n",
    "        self.a_dec = nn.MultiheadAttention(learned_dim, num_head, batch_first=True, device=device0)\n",
    "        \n",
    "        self.ffa = nn.Linear(learned_dim, learned_dim, device=device0)\n",
    "        \n",
    "        self.output = nn.Linear(learned_dim, 1, device=device0)\n",
    "        \n",
    "        # should add a length token, as the fourth dim for 3d vector\n",
    "        \n",
    "    def forward(self, s, a):\n",
    "        \"\"\"\n",
    "        batched\n",
    "        s: (B,n*+1,4), a:(B,3*)\n",
    "        due to the way I leverage it, s is of same length inside each batch: (B,n,3)\n",
    "        so that there is no mask\n",
    "        action: i dont use learned vector, so a is of size (B,3)\n",
    "        \"\"\"\n",
    "        #  I should inject a junk dim at [...,0,...] and replace it\n",
    "        # so s is of shape (B,n*+1,4), and learned_start of (1,learned_dim)\n",
    "        s = self.s_embedding(s) # (B,n*+1,d)\n",
    "        s[:,0:1,:] = self.learned_start.expand(s.shape[0],1,-1)\n",
    "           \n",
    "        a = self.a_embedding(a)  # (B,d)\n",
    "        a = torch.unsqueeze(a,1) # (B,1,d)\n",
    "        \n",
    "        s1,_ = self.s_enc1(self.s_q1(s), self.s_k1(s), self.s_v1(s), \n",
    "                           need_weights=True) # self attention\n",
    "#         print(_)\n",
    "        s1 = s + s1\n",
    "        s1 = s1 + nn.functional.gelu(self.ff1(s1))\n",
    "        \n",
    "        s2,_ = self.s_enc2(self.s_q2(s1), self.s_k2(s1), self.s_v2(s1),\n",
    "                           need_weights=True) # self attention\n",
    "        s2 = s1 + s2\n",
    "        s2 = s2 + nn.functional.gelu(self.ff2(s2))\n",
    "        \n",
    "        sa,_ = self.a_dec(self.a_q(a), self.a_sk(s2), self.a_sv(s2),\n",
    "                          need_weights=True) # cross\n",
    "        sa = a + sa\n",
    "        sa = sa + nn.functional.gelu(self.ffa(sa))\n",
    "        \n",
    "        est_flog = self.output(sa) # (B,1,1)\n",
    "        est_flog = est_flog - 0  # bias the model\n",
    "        \n",
    "        return est_flog\n",
    "\n",
    "    \n",
    "max_len_traj = 60 # zccc\n",
    "\n",
    "def preprocess_s(s):\n",
    "    \"\"\"\n",
    "    batched s:(B,n*,3)->(B,n*+1,4)\n",
    "    inject a junk dim before the first dim\n",
    "    \"\"\"\n",
    "    junk_vec = np.array([[-2,-2,-2,-2]]) # (1,4)\n",
    "    if s[0]:\n",
    "        s = np.array(s)  # (B,n,3)\n",
    "        length_in_batch = len(s[0])\n",
    "        len_token = np.ones((s.shape[0],s.shape[1],1)) * (length_in_batch/(0.5*max_len_traj) - 1)  # \n",
    "        # (B,n,3) -> (B,n,4)\n",
    "        s_new = np.concatenate([s,len_token],axis=-1)\n",
    "        # (B,n,4) -> (B,n+1,4)\n",
    "        junk = np.array([junk_vec for x in s]) # (B,1,4)\n",
    "        s_new = np.concatenate([junk,s_new],axis=1)\n",
    "\n",
    "    else:  # s = [None, None,...] -> (B,1,4)\n",
    "        s_new = np.array([junk_vec for x in s]) # (B,1,4)\n",
    "    \n",
    "    output = torch.Tensor(s_new)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\")\n",
    "model = flog()\n",
    "model.to('cuda:0')\n",
    "model = nn.DataParallel(model,device_ids=[0,1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon = 1e-6\n",
    "def rew_shape(r,difficulty='hard'):\n",
    "    if difficulty == 'hard':\n",
    "        # < 0.03 bad, > 0.06 good\n",
    "        rew = epsilon + 10**(150*r-6)\n",
    "        return rew\n",
    "\n",
    "def get_in_flow(s):\n",
    "    # enumerate s_prev and corresponding a\n",
    "    # calculate their flows\n",
    "    # return eps + sum exp flog(s,a)\n",
    "    assert s is not None\n",
    "    s_prev = [copy.deepcopy(s) for i in range(len(s))]\n",
    "    actions = [s[i] for i in range(len(s))]\n",
    "    _ = [s_prev[i].pop(i) for i in range(len(s))]\n",
    "    \n",
    "    s_prev = preprocess_s(s_prev)\n",
    "    actions = torch.Tensor(actions)   #  parallel\n",
    "    s_prev.to(device)\n",
    "    actions.to(device)\n",
    "    \n",
    "    sumflow = torch.sum(torch.exp( torch.clamp(model(s_prev,actions), min=-70, max=70) ))  # clamp\n",
    "    return epsilon + sumflow\n",
    "\n",
    "def get_out_flow(s):\n",
    "    # sample potential a \\in A(s)\n",
    "    # get their flows\n",
    "    # return actions and flogs with ln(ter), can make decision with softmax\n",
    "    terminate_r = np.log(rew_shape(proxy(s)))\n",
    "    used_points = encode_state(s)\n",
    "    a_feas = [x for x in range(11250) if x not in used_points ] # feasible actions\n",
    "    if len(a_feas)>0 and len(used_points)<max_len_traj*2: # \n",
    "#         print(len(used_points))\n",
    "        actions = [decode_action(i) for i in a_feas]\n",
    "        repeated_states = [s for i in a_feas]\n",
    "        \n",
    "        repeated_states = preprocess_s(repeated_states)\n",
    "        actions = torch.Tensor(actions)   #  parallel\n",
    "        repeated_states.to(device)\n",
    "        actions.to(device)\n",
    "        \n",
    "        flogs = torch.clamp(model(repeated_states, actions), min = -70, max = 70)  # clamp\n",
    "        del actions \n",
    "        del repeated_states\n",
    "        a_feas.append(11250) # add the termination action\n",
    "        return a_feas, torch.cat([flogs[:,0,0],torch.Tensor([terminate_r]).to(device)])\n",
    "    else:\n",
    "        return [11250], torch.Tensor([terminate_r]).to(device)\n",
    "\n",
    "def decision(a_feas,logs):\n",
    "    prob = torch.softmax(logs,0).detach().cpu().numpy()\n",
    "    prob = 0.05 * 1/len(a_feas) + 0.95 * prob\n",
    "    action = random.choices(a_feas, weights=prob, k=1)[0]\n",
    "    return decode_action(action)\n",
    "\n",
    "def trans(s,a):\n",
    "    if a is None:\n",
    "        return None\n",
    "    if s is None:\n",
    "        return [a]\n",
    "    snew = copy.deepcopy(s)\n",
    "    snew.append(a)\n",
    "    return snew\n",
    "\n",
    "def sample_traj():\n",
    "    s0 = None\n",
    "    s = s0\n",
    "    action = -1\n",
    "    while action:\n",
    "        a, logs = get_out_flow(s)\n",
    "        action = decision(a,logs)\n",
    "        del logs\n",
    "        if action:\n",
    "            s = trans(s,action)\n",
    "        else:\n",
    "            return s\n",
    "\n",
    "def parse_traj(a):\n",
    "    # to decompose the list to a sequence of states\n",
    "    if a:\n",
    "        return [a[:i] for i in range(1,len(a)+1)]\n",
    "    else:\n",
    "        return []\n",
    "        \n",
    "\n",
    "def no_explore_decision(a_feas,logs):\n",
    "    prob = torch.softmax(logs,0).detach().cpu().numpy()\n",
    "#     prob = 0.05 * 1/len(a_feas) + 0.95 * prob\n",
    "    action = random.choices(a_feas, weights=prob, k=1)[0]\n",
    "    return decode_action(action)\n",
    "\n",
    "def no_explore_sample_traj():\n",
    "    s0 = None\n",
    "    s = s0\n",
    "    action = -1\n",
    "    while action:\n",
    "        a, logs = get_out_flow(s)\n",
    "        action = no_explore_decision(a,logs)\n",
    "        del logs\n",
    "        if action:\n",
    "            s = trans(s,action)\n",
    "        else:\n",
    "            return s\n",
    "\n",
    "def sampled_sum_get_out_flow(s):\n",
    "    terminate_r = np.log(rew_shape(proxy(s)))\n",
    "    used_points = encode_state(s)\n",
    "    a_feas = [x for x in range(11250) if x not in used_points ] # feasible actions\n",
    "    add_on_num = len(a_feas)  # terminate not included\n",
    "    if len(a_feas)>0 and len(used_points)<max_len_traj*2: # \n",
    "        sampled_a = random.sample(a_feas, k=2000) # speed up\n",
    "        actions = [decode_action(i) for i in sampled_a]\n",
    "        repeated_states = [s for i in sampled_a]\n",
    "        \n",
    "        repeated_states = preprocess_s(repeated_states)\n",
    "        actions = torch.Tensor(actions)   #  parallel\n",
    "        repeated_states.to(device)\n",
    "        actions.to(device)\n",
    "        \n",
    "        flogs = torch.clamp(model(repeated_states, actions), min = -70, max = 70)  # clamp\n",
    "        del actions \n",
    "        del repeated_states\n",
    "        return epsilon + np.exp(terminate_r) + torch.sum(torch.exp(flogs)) * add_on_num/len(sampled_a)\n",
    "    else:\n",
    "        return torch.sum(torch.Tensor([epsilon + np.exp(terminate_r)]).to(device))\n",
    "\n",
    "def full_explore_sample_traj(length=max_len_traj):\n",
    "    s0 = None\n",
    "    s = s0\n",
    "    action = -1\n",
    "    while action:\n",
    "        used_points = encode_state(s)\n",
    "        a_feas = [x for x in range(11250) if x not in used_points]\n",
    "        if len(a_feas)>0 and len(used_points)< length * 2:\n",
    "            pass\n",
    "#             a_feas.append(11250) # add the termination action\n",
    "        else:\n",
    "            a_feas = [11250]\n",
    "        \n",
    "        action = random.choices(a_feas, k=1)[0]\n",
    "        action = decode_action(action)\n",
    "        if action:\n",
    "            s = trans(s,action)\n",
    "        else:\n",
    "            return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "memory = []\n",
    "sampled_terrains = []\n",
    "crit = nn.MSELoss()\n",
    "optimizer = optim.SGD(model.parameters(),lr=2e-4)\n",
    "def get_lr(x):\n",
    "    return 1\n",
    "    \n",
    "scheduler = optim.lr_scheduler.LambdaLR(optimizer=optimizer, lr_lambda=lambda epoch:get_lr(epoch))\n",
    "batch_traj = 4 # zcedit\n",
    "\n",
    "high_quality_cnt = 0\n",
    "high_quality_terrain = []\n",
    "\n",
    "writer = SummaryWriter(\"runs/run-hard1\")\n",
    "\n",
    "pre_sample = max_len_traj # \n",
    "for i in range(pre_sample):\n",
    "    for _repeat in range(1):\n",
    "        print('pre sampling')\n",
    "        traj = full_explore_sample_traj(i+1)\n",
    "#         traj = full_explore_sample_traj(max_len_traj)\n",
    "        memory.append(traj)\n",
    "        score = proxy(traj)\n",
    "        writer.add_scalar('sample/score', score, len(memory))\n",
    "        writer.add_scalar('sample/reshaped_score_log', np.log(rew_shape(score)), len(memory))\n",
    "        if traj:\n",
    "            print('sampled a traj of len',len(traj),', score', score,\n",
    "                  'reshaped score log',np.log(rew_shape(score)), '# traj',len(memory))\n",
    "        else:\n",
    "            print('get none traj, score', score, '# traj', len(memory))\n",
    "        sampled_terrains.append((traj,score))\n",
    "        if score > 0.06:\n",
    "            high_quality_cnt += 1\n",
    "            high_quality_terrain.append(traj)\n",
    "            print('hit high quality! # high quality terrains:',high_quality_cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tic = time.time()\n",
    "while len(memory)<481:\n",
    "        \n",
    "    print('walltime: [%.1f s] | sampling...'%(time.time()-tic))\n",
    "    traj = sample_traj()\n",
    "    memory.append(traj)\n",
    "    score = proxy(traj)\n",
    "    writer.add_scalar('sample/score', score, len(memory))\n",
    "    writer.add_scalar('sample/reshaped_score_log', np.log(rew_shape(score)), len(memory))\n",
    "    if traj:\n",
    "        print('sampled a traj of len',len(traj),', score', score,\n",
    "              'reshaped score log',np.log(rew_shape(score)), '# traj',len(memory))\n",
    "        writer.add_scalar('sample/len_traj', len(traj), len(memory))\n",
    "    else:\n",
    "        print('get none traj, score', score, '# traj', len(memory))\n",
    "        writer.add_scalar('sample/len_traj', 0, len(memory))\n",
    "    sampled_terrains.append((traj,score))\n",
    "    if score > 0.06:\n",
    "        high_quality_cnt += 1\n",
    "        high_quality_terrain.append(traj) # dont use this\n",
    "        print('hit high quality! # high quality terrains:',high_quality_cnt)\n",
    "\n",
    "    if len(memory)>=batch_traj:\n",
    "        print('walltime: [%.1f s] | optimizing...'%(time.time()-tic))\n",
    "        for _opt_step in range(2):\n",
    "            aaa = random.sample(memory, k=batch_traj)\n",
    "            cum_loss = 0\n",
    "            for x in aaa:\n",
    "                s_series = parse_traj(x)\n",
    "                for s in s_series:\n",
    "                    inward = torch.log(get_in_flow(s))\n",
    "                    # outward = torch.log(torch.sum(torch.exp(get_out_flow(s)[1]))+epsilon)\n",
    "                    outward = torch.log(sampled_sum_get_out_flow(s))\n",
    "                    loss = crit(inward, outward)/batch_traj\n",
    "                    cum_loss += loss.item() # *batch_traj  # get average\n",
    "                    loss.backward()\n",
    "            print('cumulative loss',cum_loss)\n",
    "            writer.add_scalar('loss/cum_loss'+str(_opt_step), cum_loss, len(memory))\n",
    "            nn.utils.clip_grad_norm_(model.parameters(), 20, norm_type=2)\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "        print('lr',scheduler.get_last_lr())\n",
    "        scheduler.step()\n",
    "        \n",
    "    if len(memory) % 30 == 0:\n",
    "        print('saving model')\n",
    "        torch.save(model, \"model_para_hard1_iter\"+str(len(memory))+\".pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# memory = memory[:600]\n",
    "# sampled_terrains = sampled_terrains[:600]\n",
    "model = torch.load('model_para_hard1_iter360.pth')\n",
    "optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "outputs = []\n",
    "outputs_len = []\n",
    "for i in range(50):\n",
    "    _ = no_explore_sample_traj()\n",
    "    score_ = proxy(_)\n",
    "    outputs.append(score_)\n",
    "    outputs_len.append(len(_))\n",
    "    print(i+1,len(_),score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('data_hard1.pickle', 'wb') as f: \n",
    "    pickle.dump({'model':model,'cpt_iter':360,'train_sample':sampled_terrains[:480],'test':(outputs,outputs_len)}, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# proxy(no_explore_sample_traj(),True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
